{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08120d47",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "\n",
    "- Add back in the draws. \n",
    "- Figure out how to use non-numerical values classes maybe? One-hot encoding\n",
    "- Modularize the code - put it into functions and that.\n",
    "- Look at columns with many Nans and get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b443bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender', 'Remarks']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23352c",
   "metadata": {},
   "source": [
    "# Import data and access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a1aff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2d9b8d0f7d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49cc1b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\joshe\\.cache\\kagglehub\\datasets\\rajeevw\\ufcdata\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rajeevw/ufcdata\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "\n",
    "names = [\"\\data.csv\", \"\\preprocessed_data.csv\", \"\\\\raw_fighter_details.csv\", \"\\\\raw_total_fight_data.csv\"]\n",
    "\n",
    "data = []\n",
    "data.append(pd.read_csv(path + names[0] ))\n",
    "data.append(pd.read_csv(path + names[1] ))\n",
    "data.append(pd.read_csv(path + names[2] ))\n",
    "data.append(pd.read_csv(path + names[3] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea03e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89675456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R_fighter',\n",
       " 'B_fighter',\n",
       " 'Referee',\n",
       " 'date',\n",
       " 'location',\n",
       " 'Winner',\n",
       " 'weight_class',\n",
       " 'B_Stance',\n",
       " 'R_Stance']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fca7ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['B_Stance'].nunique(), dat['weight_class'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20290554",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Employee data : \n",
      "      title_bout  B_avg_KD  B_avg_opp_KD  B_avg_SIG_STR_pct  \\\n",
      "0          False     0.000           0.0           0.420000   \n",
      "1          False     0.500           0.0           0.660000   \n",
      "2          False       NaN           NaN                NaN   \n",
      "3          False       NaN           NaN                NaN   \n",
      "4          False     0.125           0.0           0.535625   \n",
      "...          ...       ...           ...                ...   \n",
      "6007       False       NaN           NaN                NaN   \n",
      "6008       False       NaN           NaN                NaN   \n",
      "6009       False       NaN           NaN                NaN   \n",
      "6010       False       NaN           NaN                NaN   \n",
      "6011       False       NaN           NaN                NaN   \n",
      "\n",
      "      B_avg_opp_SIG_STR_pct  B_avg_TD_pct  B_avg_opp_TD_pct  B_avg_SUB_ATT  \\\n",
      "0                   0.49500         0.330           0.36000          0.500   \n",
      "1                   0.30500         0.300           0.50000          1.500   \n",
      "2                       NaN           NaN               NaN            NaN   \n",
      "3                       NaN           NaN               NaN            NaN   \n",
      "4                   0.57875         0.185           0.16625          0.125   \n",
      "...                     ...           ...               ...            ...   \n",
      "6007                    NaN           NaN               NaN            NaN   \n",
      "6008                    NaN           NaN               NaN            NaN   \n",
      "6009                    NaN           NaN               NaN            NaN   \n",
      "6010                    NaN           NaN               NaN            NaN   \n",
      "6011                    NaN           NaN               NaN            NaN   \n",
      "\n",
      "      B_avg_opp_SUB_ATT  B_avg_REV  ...  weight_class_Heavyweight  \\\n",
      "0                1.0000       0.00  ...                       0.0   \n",
      "1                0.0000       0.00  ...                       0.0   \n",
      "2                   NaN        NaN  ...                       1.0   \n",
      "3                   NaN        NaN  ...                       0.0   \n",
      "4                0.1875       0.25  ...                       0.0   \n",
      "...                 ...        ...  ...                       ...   \n",
      "6007                NaN        NaN  ...                       0.0   \n",
      "6008                NaN        NaN  ...                       0.0   \n",
      "6009                NaN        NaN  ...                       0.0   \n",
      "6010                NaN        NaN  ...                       0.0   \n",
      "6011                NaN        NaN  ...                       0.0   \n",
      "\n",
      "      weight_class_LightHeavyweight  weight_class_Lightweight  \\\n",
      "0                               0.0                       0.0   \n",
      "1                               0.0                       0.0   \n",
      "2                               0.0                       0.0   \n",
      "3                               0.0                       0.0   \n",
      "4                               0.0                       0.0   \n",
      "...                             ...                       ...   \n",
      "6007                            0.0                       0.0   \n",
      "6008                            0.0                       0.0   \n",
      "6009                            0.0                       0.0   \n",
      "6010                            0.0                       0.0   \n",
      "6011                            0.0                       0.0   \n",
      "\n",
      "      weight_class_Middleweight  weight_class_OpenWeight  \\\n",
      "0                           0.0                      0.0   \n",
      "1                           1.0                      0.0   \n",
      "2                           0.0                      0.0   \n",
      "3                           0.0                      0.0   \n",
      "4                           0.0                      0.0   \n",
      "...                         ...                      ...   \n",
      "6007                        0.0                      1.0   \n",
      "6008                        0.0                      1.0   \n",
      "6009                        0.0                      1.0   \n",
      "6010                        0.0                      1.0   \n",
      "6011                        0.0                      1.0   \n",
      "\n",
      "      weight_class_Welterweight  weight_class_WomenBantamweight  \\\n",
      "0                           0.0                             0.0   \n",
      "1                           0.0                             0.0   \n",
      "2                           0.0                             0.0   \n",
      "3                           0.0                             0.0   \n",
      "4                           0.0                             1.0   \n",
      "...                         ...                             ...   \n",
      "6007                        0.0                             0.0   \n",
      "6008                        0.0                             0.0   \n",
      "6009                        0.0                             0.0   \n",
      "6010                        0.0                             0.0   \n",
      "6011                        0.0                             0.0   \n",
      "\n",
      "      weight_class_WomenFeatherweight  weight_class_WomenFlyweight  \\\n",
      "0                                 0.0                          0.0   \n",
      "1                                 0.0                          0.0   \n",
      "2                                 0.0                          0.0   \n",
      "3                                 0.0                          0.0   \n",
      "4                                 0.0                          0.0   \n",
      "...                               ...                          ...   \n",
      "6007                              0.0                          0.0   \n",
      "6008                              0.0                          0.0   \n",
      "6009                              0.0                          0.0   \n",
      "6010                              0.0                          0.0   \n",
      "6011                              0.0                          0.0   \n",
      "\n",
      "      weight_class_WomenStrawweight  \n",
      "0                               0.0  \n",
      "1                               0.0  \n",
      "2                               0.0  \n",
      "3                               1.0  \n",
      "4                               0.0  \n",
      "...                             ...  \n",
      "6007                            0.0  \n",
      "6008                            0.0  \n",
      "6009                            0.0  \n",
      "6010                            0.0  \n",
      "6011                            0.0  \n",
      "\n",
      "[6012 rows x 161 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_columns = dat.select_dtypes(include=['object']).columns.tolist()\n",
    "encoding = ['B_Stance', 'R_Stance', 'weight_class']\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Apply one-hot encoding to the categorical columns\n",
    "one_hot_encoded = encoder.fit_transform(dat[encoding])\n",
    "\n",
    "#Create a DataFrame with the one-hot encoded columns\n",
    "#We use get_feature_names_out() to get the column names for the encoded data\n",
    "one_hot_dat = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(encoding))\n",
    "\n",
    "# Concatenate the one-hot encoded dataframe with the original dataframe\n",
    "dat_encoded = pd.concat([dat, one_hot_dat], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "dat_encoded = dat_encoded.drop(categorical_columns, axis=1)\n",
    "print(f\"Encoded Employee data : \\n{dat_encoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8cbe9",
   "metadata": {},
   "source": [
    "# Extract results for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0535b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_results(data):\n",
    "    results = data.Winner\n",
    "\n",
    "    results.replace(\"Red\", 0, inplace = True)\n",
    "    results.replace(\"Blue\", 1, inplace = True)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b906880",
   "metadata": {},
   "source": [
    "# Get attributes and standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f34aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(data):\n",
    "    attributes = data[data.columns.drop(\"Winner\")]\n",
    "\n",
    "    attributes.drop(columns = attributes.select_dtypes(exclude='number'), axis = 1, inplace=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    attributes = pd.DataFrame(scaler.fit_transform(attributes), columns=attributes.columns)\n",
    "    \n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e19b1",
   "metadata": {},
   "source": [
    "# Organise the main data frame we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2faf2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_to_Useful(data):\n",
    "    #Drop all draws\n",
    "    #Can keep them and then have three categories to put them into\n",
    "    data.drop(data[data[\"Winner\"] == 'Draw'].index, inplace = True)\n",
    "\n",
    "    #Look at other ways to deel with NA \n",
    "    #Replace them with the average perhaps?\n",
    "    data.dropna(axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "    data.reset_index(drop=True, inplace = True)\n",
    "    if 'index' in data.columns:\n",
    "        data.drop(columns='index', inplace=True)\n",
    "        \n",
    "    results = get_results(data)\n",
    "    attributes = get_attributes(data)\n",
    "    \n",
    "    return results, attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b17923",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e3deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Return a dictionary with 'features' and 'label' as keys\n",
    "        features = torch.tensor(self.x.iloc[index], dtype=torch.float32)\n",
    "        label = torch.tensor(self.y[index], dtype=torch.long)\n",
    "        return features, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef55567d",
   "metadata": {},
   "source": [
    "# Class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65aa5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weightings(train_dataset):\n",
    "    train_classes = [label.item() for _, label in train_dataset]\n",
    "    Counts = Counter(train_classes)\n",
    "\n",
    "    total = Counts[0] + Counts[1]\n",
    "\n",
    "    weight_0 = 100/Counts[0]\n",
    "    weight_1 = 100/Counts[1]\n",
    "\n",
    "    weightings = torch.Tensor([weight_1, weight_0])\n",
    "    \n",
    "    return weightings\n",
    "\n",
    "def data_loaders(dataset):\n",
    "    training_split = 0.9\n",
    "    length = len(dataset)\n",
    "    train_size = int(training_split * length)\n",
    "    test_size = length - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "\n",
    "    batch_size = 16  # fixed typo\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    weightings = class_weightings(train_dataset)\n",
    "    return weightings, train_loader, test_loader, train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb5380",
   "metadata": {},
   "source": [
    "# Model (Logistic Regression here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87fde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegression(torch.nn.Module):    \n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(n_inputs, n_outputs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do not apply sigmoid or softmax here; CrossEntropyLoss will handle it internally.\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc15ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445203ac",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Train model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fcd4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRAIN(model, train_loader, test_loader, weightings, test_dataset, epochs):\n",
    "    \n",
    "    # defining the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # defining Cross-Entropy loss\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight = weightings)\n",
    "\n",
    "    Loss = []\n",
    "    acc = []\n",
    "    for epoch in range(epochs):\n",
    "        for i, (attribute, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(attribute)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        Loss.append(loss.item())\n",
    "        correct = 0\n",
    "        for attribute, labels in test_loader:\n",
    "            outputs = model(attribute)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum()\n",
    "        accuracy = 100 * (correct.item()) / len(test_dataset)\n",
    "        acc.append(accuracy)\n",
    "        print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n",
    "\n",
    "    return acc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981b4ba",
   "metadata": {},
   "source": [
    "# Actually implement everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e5ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshe\\AppData\\Local\\Temp\\ipykernel_6948\\1105535225.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attributes.drop(columns = attributes.select_dtypes(exclude='number'), axis = 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "results, attributes = Data_to_Useful(data[0])\n",
    "\n",
    "dataset = CustomDataset(attributes, results)\n",
    "\n",
    "weightings, train_loader, test_loader, train_dataset, test_dataset = data_loaders(dataset)\n",
    "\n",
    "# instantiate the model\n",
    "n_inputs = train_dataset[0][0].size()[0] \n",
    "n_outputs = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f73428e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.7654337286949158. Accuracy: 65.98984771573605\n",
      "Epoch: 1. Loss: 0.4174611270427704. Accuracy: 67.85109983079526\n",
      "Epoch: 2. Loss: 0.6180501580238342. Accuracy: 68.35871404399323\n",
      "Epoch: 3. Loss: 0.35199540853500366. Accuracy: 69.03553299492386\n",
      "Epoch: 4. Loss: 0.5183919668197632. Accuracy: 69.20473773265651\n",
      "Epoch: 5. Loss: 0.4864419102668762. Accuracy: 69.37394247038917\n",
      "Epoch: 6. Loss: 0.3587799370288849. Accuracy: 69.37394247038917\n",
      "Epoch: 7. Loss: 0.4860880970954895. Accuracy: 69.37394247038917\n",
      "Epoch: 8. Loss: 0.4780825674533844. Accuracy: 69.54314720812182\n",
      "Epoch: 9. Loss: 0.690021812915802. Accuracy: 69.20473773265651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.20473773265651"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = LogisticRegression(n_inputs, n_outputs)\n",
    "net.apply(init_weights)\n",
    "TRAIN(net, train_loader, test_loader, weightings, test_dataset, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ed31f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.7011318802833557. Accuracy: 60.575296108291035\n",
      "Epoch: 1. Loss: 0.49423137307167053. Accuracy: 65.98984771573605\n",
      "Epoch: 2. Loss: 0.47340574860572815. Accuracy: 68.18950930626058\n",
      "Epoch: 3. Loss: 0.6023159027099609. Accuracy: 68.8663282571912\n",
      "Epoch: 4. Loss: 0.5837768912315369. Accuracy: 69.20473773265651\n",
      "Epoch: 5. Loss: 0.40871766209602356. Accuracy: 68.69712351945854\n",
      "Epoch: 6. Loss: 0.58094722032547. Accuracy: 69.03553299492386\n",
      "Epoch: 7. Loss: 0.48542550206184387. Accuracy: 68.8663282571912\n",
      "Epoch: 8. Loss: 0.48605459928512573. Accuracy: 68.52791878172589\n",
      "Epoch: 9. Loss: 0.48619788885116577. Accuracy: 69.20473773265651\n",
      "Epoch: 10. Loss: 0.6333357095718384. Accuracy: 68.69712351945854\n",
      "Epoch: 11. Loss: 0.8310732245445251. Accuracy: 69.20473773265651\n",
      "Epoch: 12. Loss: 0.6852930784225464. Accuracy: 68.8663282571912\n",
      "Epoch: 13. Loss: 0.4277653098106384. Accuracy: 69.20473773265651\n",
      "Epoch: 14. Loss: 0.4026275873184204. Accuracy: 68.8663282571912\n",
      "Epoch: 15. Loss: 0.2612156867980957. Accuracy: 69.20473773265651\n",
      "Epoch: 16. Loss: 0.3097602128982544. Accuracy: 69.20473773265651\n",
      "Epoch: 17. Loss: 0.5597795248031616. Accuracy: 69.20473773265651\n",
      "Epoch: 18. Loss: 0.5029812455177307. Accuracy: 69.20473773265651\n",
      "Epoch: 19. Loss: 0.5223084092140198. Accuracy: 68.69712351945854\n",
      "Epoch: 20. Loss: 0.6374003887176514. Accuracy: 69.37394247038917\n",
      "Epoch: 21. Loss: 0.4683595895767212. Accuracy: 69.20473773265651\n",
      "Epoch: 22. Loss: 0.5612707734107971. Accuracy: 69.20473773265651\n",
      "Epoch: 23. Loss: 0.4020421504974365. Accuracy: 69.20473773265651\n",
      "Epoch: 24. Loss: 0.43926772475242615. Accuracy: 69.37394247038917\n",
      "Epoch: 25. Loss: 0.507590651512146. Accuracy: 69.20473773265651\n",
      "Epoch: 26. Loss: 0.5727583765983582. Accuracy: 69.20473773265651\n",
      "Epoch: 27. Loss: 0.36371883749961853. Accuracy: 69.20473773265651\n",
      "Epoch: 28. Loss: 0.598732590675354. Accuracy: 69.37394247038917\n",
      "Epoch: 29. Loss: 0.3396010398864746. Accuracy: 69.03553299492386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.03553299492386"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = LogisticRegression(n_inputs, n_outputs)\n",
    "net.apply(init_weights)\n",
    "TRAIN(net, train_loader, test_loader, weightings, test_dataset, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc1b5c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scores = []\\n\\nfor i in range(1, 5):\\n    print(f\"\\n {i} \\n\")\\n    net = Net(n_inputs, n_outputs, 2, i)\\n    scores.append(TRAIN(net, train_loader, test_loader, weightings, test_dataset))'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scores = []\n",
    "\n",
    "for i in range(1, 5):\n",
    "    print(f\"\\n {i} \\n\")\n",
    "    net = Net(n_inputs, n_outputs, 2, i)\n",
    "    scores.append(TRAIN(net, train_loader, test_loader, weightings, test_dataset))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1afd0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "771b27e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define ranges for width and depth\\nwidth_range = [2, 4, 8, 16]  # Example widths\\ndepth_range = [1, 2, 4, 8]   # Example depths\\n\\n# Initialize a 2D array to store accuracies\\naccuracy_matrix = np.zeros((len(width_range), len(depth_range)))\\n\\n# Iterate over width and depth\\nfor i, width in enumerate(width_range):\\n    print(f\\' -------------------------WIDTH = {width} -------------------------\\')\\n    for j, depth in enumerate(depth_range):\\n        print(f\\' ------------DEPTH = {depth} -----------\\')\\n        net = Net(n_inputs, n_outputs, width, depth)\\n        \\n        # Train the model\\n        acc = TRAIN(net, train_loader, test_loader, weightings, test_dataset, epochs = 20)\\n        print(acc)\\n        # Store the final accuracy\\n        accuracy_matrix[i, j] = acc\\n\\n# Create a heatmap using seaborn\\nplt.figure(figsize=(10, 6))\\nsns.heatmap(\\n    accuracy_matrix,\\n    annot=True,\\n    fmt=\".2f\",\\n    xticklabels=depth_range,\\n    yticklabels=width_range,\\n    cmap=\"YlGnBu\"\\n)\\nplt.title(\"Final Accuracy Heatmap\")\\nplt.xlabel(\"Depth\")\\nplt.ylabel(\"Width\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Define ranges for width and depth\n",
    "width_range = [2, 4, 8, 16]  # Example widths\n",
    "depth_range = [1, 2, 4, 8]   # Example depths\n",
    "\n",
    "# Initialize a 2D array to store accuracies\n",
    "accuracy_matrix = np.zeros((len(width_range), len(depth_range)))\n",
    "\n",
    "# Iterate over width and depth\n",
    "for i, width in enumerate(width_range):\n",
    "    print(f' -------------------------WIDTH = {width} -------------------------')\n",
    "    for j, depth in enumerate(depth_range):\n",
    "        print(f' ------------DEPTH = {depth} -----------')\n",
    "        net = Net(n_inputs, n_outputs, width, depth)\n",
    "        \n",
    "        # Train the model\n",
    "        acc = TRAIN(net, train_loader, test_loader, weightings, test_dataset, epochs = 20)\n",
    "        print(acc)\n",
    "        # Store the final accuracy\n",
    "        accuracy_matrix[i, j] = acc\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    accuracy_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    xticklabels=depth_range,\n",
    "    yticklabels=width_range,\n",
    "    cmap=\"YlGnBu\"\n",
    ")\n",
    "plt.title(\"Final Accuracy Heatmap\")\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Width\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005e204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
